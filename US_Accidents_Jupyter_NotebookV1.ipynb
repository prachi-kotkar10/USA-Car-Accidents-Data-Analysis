{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fa3d1b",
   "metadata": {},
   "source": [
    "# Group-1 : US Car Accidents Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d4e86",
   "metadata": {},
   "source": [
    "Project Members:\n",
    "     1) Ajinkya Desai,\n",
    "     2) Akash Bharsakle,\n",
    "     3) Asawari Kadam,\n",
    "     4) Prachi Kotkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5131e657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%autosave 0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.tree as tree\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626d5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('US_Accidents_March23.csv',index_col=0, parse_dates=True)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.min_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7a052",
   "metadata": {},
   "source": [
    "## 1. Data Set Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd57e2f",
   "metadata": {},
   "source": [
    "This dataset includes information about car accidents across the entire United States, covering 49 states (Except Alaska) spanning over a duration starting from February 2016 to March 2023. The dataset contains approximately 7.7 million accident records from all over USA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866dd706",
   "metadata": {},
   "source": [
    "#### We have divided all of the important columns in 4 categories which are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0da0b4",
   "metadata": {},
   "source": [
    "**General Info**\n",
    "* Severity : Shows the severity of the accident, where 1 indicates the least impact on traffic and 4 indicates the most.\n",
    "* Start_Time : Start time of the accident in local time zone.\n",
    "* End_Time : End time of the accident in local time zone.\n",
    "* Start_Lat : Shows latitude in GPS coordinate of the start point.\n",
    "* Start_Lng : Shows longitude in GPS coordinate of the start point.\n",
    "* Distance : The length of the road extent affected by the accident in miles.\n",
    "* Street : Name of the Street accident happened on.\n",
    "* City : Shows the city in address field.\n",
    "* State : Shows the state in address field.\n",
    "* Zipcode : Shows the zipcode in address field.\n",
    "* Timezone : Shows timezone based on the location of the accident (eastern, central, etc.).\n",
    "\n",
    "**Weather Situations**\n",
    "* Temperature : Shows the temperature (in Fahrenheit).\n",
    "* Wind_Chill : Shows the wind chill (in Fahrenheit).\n",
    "* Humidity : Shows the humidity (in percentage).\n",
    "* Pressure : Shows the air pressure (in inches).\n",
    "* Visibility : Shows visibility (in miles).\n",
    "* Wind_Speed : Shows wind speed (in miles per hour).\n",
    "* Weather_Condition : Shows the weather condition (rain, snow, thunderstorm, fog, etc.)\n",
    "\n",
    "**Road Conditions**\n",
    "* Amenity : indicates presence of amenity in a nearby location.\n",
    "* Bump : indicates presence of speed bump or hump in a nearby location.\n",
    "* Crossing : indicates presence of crossing in a nearby location.\n",
    "* Give_Way : indicates presence of give_way in a nearby location.\n",
    "* Junction : indicates presence of junction in a nearby location.\n",
    "* No_Exit : indicates no exit in a nearby location.\n",
    "* Railway : indicates presence of railway route in a nearby location.\n",
    "* Roundabout : indicates presence of roundabout in a nearby location.\n",
    "* Station : indicates presence of station in a nearby location.\n",
    "* Stop : indicates presence of stop sign in a nearby location.\n",
    "* Traffic_Calming : indicates whether traffic calming measures are present in the vicinity of a specific accident location\n",
    "* Traffic_Signal : indicates presence of traffic signal in a nearby location\n",
    "* Turning_Loop : indicates presence of turning loop in a nearby location.\n",
    "\n",
    "**Period of the Day**\n",
    "* Sunrise_Sunset : period of day (i.e. day or night) based on sunrise/sunset.\n",
    "* Civil_Twilight : Shows the period of day (i.e. day or night) based on civil twilight.\n",
    "* Nautical_Twilight : Shows the period of day (i.e. day or night) based on nautical twilight.\n",
    "* Astronomical_Twilight : Shows the period of day (i.e. day or night) based on Astronomical Twilight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6c6ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7728394, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b3416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat',\n",
       "       'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description',\n",
       "       'Street', 'City', 'County', 'State', 'Zipcode', 'Country',\n",
       "       'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Temperature(F)',\n",
       "       'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
       "       'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)',\n",
       "       'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way',\n",
       "       'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop',\n",
       "       'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e34d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c29868",
   "metadata": {},
   "source": [
    "### Cleaning the dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38cdf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.87</td>\n",
       "      <td>-84.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.93</td>\n",
       "      <td>-82.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.06</td>\n",
       "      <td>-84.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.75</td>\n",
       "      <td>-84.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.63</td>\n",
       "      <td>-84.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0      39.87     -84.06      NaN      NaN          0.01  ...      False   \n",
       "1      39.93     -82.83      NaN      NaN          0.01  ...      False   \n",
       "2      39.06     -84.03      NaN      NaN          0.01  ...      False   \n",
       "3      39.75     -84.21      NaN      NaN          0.01  ...      False   \n",
       "4      39.63     -84.19      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbb839",
   "metadata": {},
   "source": [
    "Replacing the missing values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15119fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(to_replace=['?',' '],value=np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a8ad8",
   "metadata": {},
   "source": [
    "Checking how many NaN actually exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355a73f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "Source                         0\n",
       "Severity                       0\n",
       "Start_Time                     0\n",
       "End_Time                       0\n",
       "Start_Lat                      0\n",
       "Start_Lng                      0\n",
       "End_Lat                  3402762\n",
       "End_Lng                  3402762\n",
       "Distance(mi)                   0\n",
       "Description                    5\n",
       "Street                     10869\n",
       "City                         253\n",
       "County                         0\n",
       "State                          0\n",
       "Zipcode                     1915\n",
       "Country                        0\n",
       "Timezone                    7808\n",
       "Airport_Code               22635\n",
       "Weather_Timestamp         120228\n",
       "Temperature(F)            163853\n",
       "Wind_Chill(F)            1999019\n",
       "Humidity(%)               174144\n",
       "Pressure(in)              140679\n",
       "Visibility(mi)            177098\n",
       "Wind_Direction            175206\n",
       "Wind_Speed(mph)           571233\n",
       "Precipitation(in)        2203586\n",
       "Weather_Condition         173459\n",
       "Amenity                        0\n",
       "Bump                           0\n",
       "Crossing                       0\n",
       "Give_Way                       0\n",
       "Junction                       0\n",
       "No_Exit                        0\n",
       "Railway                        0\n",
       "Roundabout                     0\n",
       "Station                        0\n",
       "Stop                           0\n",
       "Traffic_Calming                0\n",
       "Traffic_Signal                 0\n",
       "Turning_Loop                   0\n",
       "Sunrise_Sunset             23246\n",
       "Civil_Twilight             23246\n",
       "Nautical_Twilight          23246\n",
       "Astronomical_Twilight      23246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e8bbc",
   "metadata": {},
   "source": [
    "Few of the columns have only 1 class like 'Country' and 'Turning_Loop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a905a411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country 1\n",
      "Timezone 5\n",
      "Bump 2\n",
      "Crossing 2\n",
      "Junction 2\n",
      "No_Exit 2\n",
      "Railway 2\n",
      "Roundabout 2\n",
      "Station 2\n",
      "Stop 2\n",
      "Traffic_Signal 2\n",
      "Turning_Loop 1\n",
      "Sunrise_Sunset 3\n"
     ]
    }
   ],
   "source": [
    "categorical_col = ['Country','Timezone','Bump','Crossing','Junction','No_Exit','Railway','Roundabout','Station',\\\n",
    "             'Stop','Traffic_Signal', 'Turning_Loop','Sunrise_Sunset']\n",
    "for i in categorical_col:\n",
    "    print(i,df[i].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae551f",
   "metadata": {},
   "source": [
    "Dropping the below columns as some of those('ID','Description', 'Wind_Direction', 'End_Lng', 'End_Lat','Country', 'Source', 'County', 'ID', 'Airport_Code','Precipitation(in)') did not contribute much for insights, some ('Turning_Loop','Country') have only one unique value and 'Weather_Timestamp' has very similar time as \"Start_Time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54527c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ID','Description', 'Wind_Direction', 'End_Lng', 'End_Lat', 'Weather_Timestamp',\\\n",
    "                 'Country', 'Source', 'County', 'ID', 'Airport_Code','Precipitation(in)'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ac669",
   "metadata": {},
   "source": [
    "Dropping Duplicates from the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e74f66",
   "metadata": {},
   "source": [
    "Renaming the columns to perform calculations and have easy access (Removing brackets from the column names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bf44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Distance(mi)':'Distance','Temperature(F)':'Temperature','Wind_Chill(F)':'Wind_Chill',\\\n",
    "                  'Humidity(%)':'Humidity','Pressure(in)':'Pressure','Visibility(mi)':'Visibility',\\\n",
    "                   'Wind_Speed(mph)':'Wind_Speed'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefda086",
   "metadata": {},
   "source": [
    "Dropping NaNs from the columns with insignificant number of NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any',subset=['City'],inplace=True)\n",
    "df.dropna(how='any',subset=['Street'],inplace=True)\n",
    "df.dropna(how='any',subset=['Zipcode'],inplace=True)\n",
    "df.dropna(how='any',subset=['Timezone'],inplace=True)\n",
    "df.dropna(how='any',subset=['Civil_Twilight'],inplace=True)\n",
    "df.dropna(how='any',subset=['Astronomical_Twilight'],inplace=True)\n",
    "df.dropna(how='any',subset=['Nautical_Twilight'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6c7f9",
   "metadata": {},
   "source": [
    "Filling in NaN's with the mean and median values of the respective columns as the NaNs in these columns are significant in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Temperature'].fillna(df['Temperature'].mean(), inplace=True)\n",
    "df['Wind_Chill'].fillna(df['Wind_Chill'].mean(), inplace=True)\n",
    "df['Humidity'].fillna(df['Humidity'].mean(), inplace=True)\n",
    "df['Pressure'].fillna(df['Pressure'].mean(), inplace=True)\n",
    "df['Visibility'].fillna(df['Visibility'].median(), inplace=True)\n",
    "df['Wind_Speed'].fillna(df['Wind_Speed'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad9716",
   "metadata": {},
   "source": [
    "Filling in NaN's with forward filling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weather_Condition'].fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b80c1",
   "metadata": {},
   "source": [
    "Formatting date-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Start_Time = pd.to_datetime(df.Start_Time)\n",
    "df.End_Time = pd.to_datetime(df.End_Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b9b6a",
   "metadata": {},
   "source": [
    "Checking the number of NaN's present after the data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214895e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cd9c9",
   "metadata": {},
   "source": [
    "Final Shape of the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d29eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3148ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f60ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973ed7f",
   "metadata": {},
   "source": [
    "Below bar chart is to give a brief idea of the accident counts over the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df = pd.DataFrame(df.Start_Time.dt.month.value_counts()).reset_index()\n",
    "month_df.sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = month_df.rename(columns={'Start_Time':'count','index':'month'}).sort_values(by='month', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e4dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting the months of interest(only months with min and max counts) here\n",
    "\n",
    "sns.catplot(x='month',y='count',data=month,kind='bar',\\\n",
    "            palette = [\"lightpink\", \"lightpink\",\"lightpink\",\"lightpink\",\"lightpink\",\"lightpink\",\"blue\",\\\n",
    "                      \"lightpink\", \"lightpink\",\"lightpink\",\"lightpink\",\"red\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fe2bc",
   "metadata": {},
   "source": [
    "## 1) Analysis of Accident counts by zone and Road Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef24e3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(nrows=4, ncols=2, figsize = (16,20))\n",
    "\n",
    "road_conditions = ['Bump', 'Crossing', 'Give_Way', 'Junction', 'Stop', 'No_Exit', 'Traffic_Signal', 'Turning_Loop']\n",
    "colors = [('#6662b3', '#00FF00'), ('#7881ff', '#0e1ce8'), ('#18f2c7', '#09ad8c'), ('#08ff83', '#02a352'), ('#ffcf87', '#f5ab3d'),\n",
    "         ('#f5f53d', '#949410'), ('#ff9187', '#ffc7c2'), ('tomato', '#008000')]    \n",
    "count = 0\n",
    "\n",
    "def func(pct, allvals):\n",
    "    absolute = int(round(pct/100*np.sum(allvals), 2))\n",
    "    return \"{:.2f}%\\n({:,d} Cases)\".format(pct, absolute)    \n",
    "\n",
    "for i in [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]:\n",
    "    \n",
    "    size = list(df[road_conditions[count]].value_counts())\n",
    "    if len(size) != 2:\n",
    "        size.append(0)\n",
    "    \n",
    "    labels = ['False', 'True']\n",
    "    \n",
    "    \n",
    "    \n",
    "    i.pie(size, labels = labels, colors = colors[count],\n",
    "                    autopct = lambda pct: func(pct, size), labeldistance=1.1,\n",
    "                    textprops={'fontsize': 12}, explode=[0, 0.2])\n",
    "\n",
    "    title = '\\nPresence of {}'.format(road_conditions[count])\n",
    "\n",
    "    i.set_title(title, fontsize = 18, color='grey')\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f032429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61eb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "Northwest =['OR','WA','ID']\n",
    "Southwest =['CA','NV','AZ','UT']\n",
    "North_Central = ['MT','WY', 'CO','ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO']\n",
    "South_Central = ['NM','TX','OK','LA']\n",
    "Midwest =['WI', 'IL','IN', 'OH','MI']\n",
    "Southeast = ['AR','TN', 'MS', 'AL', 'FL', 'GA', 'SC', 'NC']\n",
    "Northeast = [ 'DC','KY', 'VA', 'WV', 'MD', 'DE', 'PA', 'NJ', 'NY', 'CT', 'RI', 'MA', 'NH', 'VT', 'ME']               \n",
    "                 \n",
    "\n",
    "df_zone['Zone'] = np.select(\n",
    "    [df_zone['State'].isin(Northwest), df_zone['State'].isin(Southwest), df_zone['State'].isin(North_Central), df_zone['State'].isin(South_Central),df_zone['State'].isin(Midwest),df_zone['State'].isin(Southeast),df_zone['State'].isin(Northeast)],\n",
    "    ['Northwest', 'Southwest', 'North Central', 'South Central','Midwest','Southeast','Northeast'],\n",
    "    default='Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Grouping by Zone and calculating the counts for each parameter\n",
    "grouped_df = df_zone.groupby('Zone')[['Traffic_Signal', 'Crossing', 'Junction']].sum().reset_index()\n",
    "\n",
    "# Melting the DataFrame for better visualization\n",
    "melted_df = pd.melt(grouped_df, id_vars='Zone', var_name=' Road Parameters', value_name='Count')\n",
    "\n",
    "# Plotting the bar graph\n",
    "ax = sns.barplot(x='Zone', y='Count', hue=' Road Parameters', data=melted_df)\n",
    "plt.title('Accidents Count by Zone and Road Parameters')\n",
    "plt.xlabel('Zone')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Calculating and displaying the percentages on each bar\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height, f'{height / grouped_df[\"Traffic_Signal\"].sum() * 100:.2f}%', \n",
    "            ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f557de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_zone.copy()\n",
    "zone_mapping = {'Northwest':1, 'Southwest':2, 'North Central':3, 'South Central':4,'Midwest':5,'Southeast':6,\\\n",
    "                'Northeast':7}\n",
    "df2['Zone'] = df2['Zone'].map(zone_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['Start_Time','Start_Lat','Start_Lng','Street','City','State','Zipcode',\\\n",
    "                  'Wind_Speed','Distance','Railway','No_Exit','Timezone','Temperature','Visibility',\\\n",
    "                  'Weather_Condition','Civil_Twilight','Nautical_Twilight', 'Astronomical_Twilight','End_Time',\\\n",
    "                  'Wind_Chill','Humidity','Pressure','Turning_Loop'],inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076012e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Bump']= df2['Bump']+0.0\n",
    "df2['Crossing'] = df2['Crossing'] + 0.0\n",
    "df2['Give_Way'] = df2['Give_Way'] + 0.0\n",
    "df2['Junction'] = df2['Junction'] + 0.0\n",
    "df2['Roundabout'] = df2['Roundabout'] + 0.0\n",
    "df2['Station'] = df2['Station'] + 0.0\n",
    "df2['Stop'] = df2['Stop'] + 0.0\n",
    "df2['Traffic_Signal'] = df2['Traffic_Signal'] + 0.0\n",
    "df2['Traffic_Calming'] = df2['Traffic_Calming'] +0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b28587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Sunrise_Sunset'] = df2['Sunrise_Sunset'].map({'Day': 1, 'Night': 0})\n",
    "df2['Sunrise_Sunset'].fillna(df2['Sunrise_Sunset'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb75b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt= tree.DecisionTreeClassifier(max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop('Zone',axis=1)\n",
    "Y = df2.Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122eff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_feature_names = list(X.columns)\n",
    "dt_target_names = [str(s) for s in Y.unique()]\n",
    "tree.export_graphviz(dt, out_file='tree.dot', \n",
    "    feature_names=dt_feature_names, class_names=dt_target_names,\n",
    "    filled=True)  \n",
    "graph = pydotplus.graph_from_dot_file('tree.dot')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28653af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows for Zone 7 and Zone 4 with Traffic_Signal equal to 1 for validation of the decision tree\n",
    "selected_zones_traffic_signal_1 = df2[(df2['Zone'].isin([7, 4])) & (df2['Traffic_Signal'] == 1)]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=selected_zones_traffic_signal_1, x='Zone')\n",
    "\n",
    "plt.title('Count of Accidents with Traffic Signal = 1 for Zone 7 and Zone 4')\n",
    "plt.xlabel('Zone')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063379f7",
   "metadata": {},
   "source": [
    "**Insight**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122da3de",
   "metadata": {},
   "source": [
    "- You will be amazed with the fact that almost 34% of accidents have occoured even though there were Traffic Signal, Crossing and Junction present in location.\n",
    "((Traffic Signal) 14.84 + (Crossing) 11.35 + (Junction) 7.35 =33.54 %)\n",
    "\n",
    "- On detailed analysis of these factors by diving the US states into 7 zones based on geographical conditions, it is quite evident from the graph that 68.47% of accidents in south east region occurred even though these 3 factors(Traffic signal,Crossing and Junction) were present there.\n",
    "South East - Traffic Signal) 31.27 + (Crossing) 28.7 + (Junction) 8.50 = 68.47 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a1a57",
   "metadata": {},
   "source": [
    "**Recommendation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33eb54",
   "metadata": {},
   "source": [
    "More penalties must be levied by the Government for traffic rules violations( specially in south east region) so that people would be more cautious while driving and accidents count would be less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cad3a",
   "metadata": {},
   "source": [
    "## 2) Accidents Analysis based on Road Bumps (Speed Breakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_counts = df['Severity'].value_counts()\n",
    "severity_counts\n",
    "\n",
    "# Most accidents are of severity '2' and '3', \n",
    "# with very few cases of severity '1' and '4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart = df.groupby('Severity')['Severity'].count().\\\n",
    "            plot(kind='pie',figsize=(6, 6),autopct='%1.0f%%',cmap=\"Blues\")\n",
    "\n",
    "labels = severity_counts.index.tolist()\n",
    "# Adding a title to the pie chart\n",
    "pie_chart.set_title('Distribution of Accident Severity', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing accidents based on city or county\n",
    "citywise_accidents = df['City'].value_counts().head(10)  # Top 10 cities\n",
    "citywise_accidents\n",
    "# Citywise distribution plot\n",
    "sns.barplot(y=citywise_accidents.index, x=citywise_accidents.values)\n",
    "plt.title('Top 10 Cities with Most Accidents')\n",
    "plt.xlabel('Number of Accidents')\n",
    "plt.ylabel('City')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e19967",
   "metadata": {},
   "source": [
    "Hotspot Analysis: Major citis like Miami, Houston, LA identify areas with high accident frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e713fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'City' and counting the number of accidents\n",
    "city_accidents = df.groupby('City').size().reset_index(name='Accident_Count')\n",
    "\n",
    "# 'Start_Lat' and 'Start_Lng' give the coordinates for the accidents\n",
    "cities_df = df[['City', 'Start_Lat', 'Start_Lng']].drop_duplicates(subset=['City'])\n",
    "\n",
    "# Merging the city locations with the accident counts\n",
    "plotting_df = pd.merge(cities_df, city_accidents, on='City')\n",
    "\n",
    "# Setting Mapbox access token here\n",
    "px.set_mapbox_access_token('pk.eyJ1IjoiYWppbmt5YWRlc2FpIiwiYSI6ImNscGd6OHJlbzAyOXoyanJ4a3E5eHM1Y3kifQ.ZzUvGP5rqkSuSmsfAYZ3HA')\n",
    "\n",
    "# Creating a scatter mapbox to visualize accidents by city\n",
    "fig = px.scatter_mapbox(plotting_df,\n",
    "                        lat='Start_Lat',\n",
    "                        lon='Start_Lng',\n",
    "                        size='Accident_Count',\n",
    "                        color='Accident_Count',\n",
    "                        color_continuous_scale=px.colors.sequential.Tealgrn,\n",
    "                        size_max=20,\n",
    "                        zoom=3,\n",
    "                        hover_name='City',\n",
    "#                         height=1200,  # You may adjust this value as needed\n",
    "#                         width=800, \n",
    "                        title='Accidents in the United States by City',\n",
    "                        mapbox_style='light')\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_severity_counts = df.groupby(['State','Severity']).size().reset_index(name='Accident_Count')\n",
    "\n",
    "# First, sorting the DataFrame by 'State' and 'State_Severity_Count' in descending order\n",
    "state_severity_counts_sorted = state_severity_counts.sort_values(by=['State', 'Accident_Count'], ascending=[True, False])\n",
    "\n",
    "# Now, dropping duplicate states, keeping the first occurrence (which will be the highest severity due to sorting)\n",
    "highest_severity_per_state = state_severity_counts_sorted.drop_duplicates(subset='State')\n",
    "\n",
    "\n",
    "highest_severity_per_state_sorted = highest_severity_per_state.sort_values(by='Accident_Count', ascending=False)\n",
    "\n",
    "len(highest_severity_per_state_sorted)\n",
    "highest_severity_per_state_sorted.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_accident_counts = df.groupby(['State',]).size().reset_index(name='Accident_Count')\n",
    "state_accident_counts_sorted = state_accident_counts.sort_values(by='Accident_Count', ascending=False)\n",
    "state_accident_counts_sorted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(state_accident_counts, \n",
    "                    locations=\"State\",\n",
    "                    locationmode='USA-states',\n",
    "                    color=\"Accident_Count\", \n",
    "                    hover_name=\"State\",\n",
    "                    scope='usa',\n",
    "                    title='US Accidents Statewise Count',\n",
    "                    width=800,\n",
    "                    height=400,\n",
    "                    color_continuous_scale=px.colors.sequential.Tealgrn,\n",
    "                   labels={'Accident_Count': 'Number of Accidents'}\n",
    "                   )\n",
    "                    \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc87a1e",
   "metadata": {},
   "source": [
    "It seems that most accidents with severity 2 are happending in major states like California, Texas, Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(15, 15))  # Making the plot larger\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "\n",
    "# Improving the aesthetics\n",
    "plt.title('Correlation Matrix of Accident Data', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)  # Rotating x labels for better readability\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()  # Adjusts the plot to ensure everything fits without overlapping\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8fdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 highest correlations\n",
    "# Flattening the correlation matrix and sort values\n",
    "corr_pairs = correlation_matrix.unstack().sort_values(ascending=False).drop_duplicates()\n",
    "\n",
    "# Removing self-correlation pairs\n",
    "corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n",
    "\n",
    "# Getting the top 5 highest correlations\n",
    "highest_corr_pairs = corr_pairs.head(5)\n",
    "print(\"Top 5 highest correlations:\")\n",
    "print(highest_corr_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715855a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names of the columns involved in the highest correlations\n",
    "highest_corr_columns = set()\n",
    "for (col1, col2) in highest_corr_pairs.index:\n",
    "    highest_corr_columns.add(col1)\n",
    "    highest_corr_columns.add(col2)\n",
    "\n",
    "# Creating a new DataFrame with the highest correlated columns\n",
    "highest_corr_df = correlation_matrix.loc[highest_corr_columns, highest_corr_columns]\n",
    "\n",
    "# Plotting a heatmap for the highest correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highest_corr_df, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10) \n",
    "plt.title('Heatmap of Highest Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32c543",
   "metadata": {},
   "source": [
    "**Temperature and Wind Chill**: There is a high positive correlation between temperature and wind chill, which is expected as they are both related to weather conditions. However, there is counterintutive finding on accidents vs weather. Most acccidents are happening at moderate temperature 50 F (rather than extreme weathers) in concenterated cities and states.\n",
    "\n",
    "**Traffic Calming and Bump**: Traffic calming measures have a strong positive correlation with the presence of bumps. This indicates that bumps are a commonly used traffic calming measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69217161",
   "metadata": {},
   "source": [
    "**BUMP IMPACT ON ACCIDENTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a2df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bump_incident_counts = df.groupby('Bump').size().reset_index(name='Number_of_Incidents')\n",
    "Bump_incident_counts\n",
    "barplot=sns.barplot(x='Bump', y='Number_of_Incidents', data=Bump_incident_counts)\n",
    "plt.title('Impact of Bumps on Number of Incidents')\n",
    "plt.xlabel('Bump Presence')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.yscale('log')\n",
    "# Annotating each bar with the value\n",
    "for index, row in Bump_incident_counts.iterrows():\n",
    "    barplot.text(index, row.Number_of_Incidents, row.Number_of_Incidents, color='black', ha=\"center\")\n",
    "plt.show()\n",
    "\n",
    "# Traffic Calming and Bumps: Bumps are effectively used to calm traffic. \n",
    "# The government should assess and possibly increase their use, especially near schools and residential areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'State' and 'Bump' and count the number of incidents\n",
    "state_bump_counts = df.groupby(['State', 'Bump']).size().reset_index(name='Number_of_Incidents')\n",
    "state_bump_counts.sort_values(by=['Number_of_Incidents'],ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'State' and 'Bump' and count the number of incidents\n",
    "state_bump_counts = df.groupby(['State', 'Bump']).size().reset_index(name='Number_of_Incidents')\n",
    "\n",
    "# Sorting the results by the number of incidents, not state, to get the top incidents\n",
    "state_bump_counts_sorted = state_bump_counts.sort_values('Number_of_Incidents', ascending=False).head(10)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 10))\n",
    "barplot = sns.barplot(data=state_bump_counts_sorted, x='State', y='Number_of_Incidents', hue='Bump')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Statewise Impact of Bumps on Number of Incidents')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.legend(title='Bump Presence', loc='upper left', bbox_to_anchor=(0.87, 1))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjusting the rect parameter to make space for the legend\n",
    "\n",
    "\n",
    "# Annotating the top 3 states\n",
    "top_states = state_bump_counts_sorted.head(3)\n",
    "for i, (index, row) in enumerate(top_states.iterrows()):\n",
    "    # Getting the x location of the bar\n",
    "    x = i\n",
    "    # Annotating with state name and incident count\n",
    "    plt.text(x, row['Number_of_Incidents'], f\"{row['State']}: {int(row['Number_of_Incidents'])}\", color='black', ha=\"left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f7bfd",
   "metadata": {},
   "source": [
    "##### Comparison number of accidents in region without and with inclusion of Signal Bumps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data to include only rows with 'Bumps' being False\n",
    "no_bump_data = df[df['Bump'] == False]\n",
    "\n",
    "# Defining regions based on the median values of latitude and longitude\n",
    "median_lat = no_bump_data['Start_Lat'].median()\n",
    "median_lng = no_bump_data['Start_Lng'].median()\n",
    "\n",
    "# Functioning to determine the region based on latitude and longitude\n",
    "def determine_region(lat, lng, median_lat, median_lng):\n",
    "    if lat >= median_lat and lng >= median_lng:\n",
    "        return 'North-East'\n",
    "    elif lat < median_lat and lng >= median_lng:\n",
    "        return 'South-East'\n",
    "    elif lat >= median_lat and lng < median_lng:\n",
    "        return 'North-West'\n",
    "    else:\n",
    "        return 'South-West'\n",
    "\n",
    "# Applying the function to create a new 'Region' column\n",
    "no_bump_data['Region'] = no_bump_data.apply(lambda x: determine_region(x['Start_Lat'], x['Start_Lng'], median_lat, median_lng), axis=1)\n",
    "\n",
    "# Using KMeans to cluster the data based on 'Latitude' and 'Longitude'\n",
    "kmeans = KMeans(n_clusters=4)  # We choose 4 to match the number of regions we've defined\n",
    "no_bump_data['Cluster'] = kmeans.fit_predict(no_bump_data[['Start_Lat', 'Start_Lng']])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# We are using hue to color the data points based on the new 'Region' column\n",
    "sns.scatterplot(data=no_bump_data, x='Start_Lng', y='Start_Lat', hue='Region', style='Cluster',\n",
    "                palette='Set1', alpha=0.6)\n",
    "\n",
    "# Plotting the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Counting the number of accidents per cluster\n",
    "cluster_accident_counts = no_bump_data.groupby('Cluster').size()\n",
    "\n",
    "# Annotating the cluster centers with the accident counts\n",
    "for i, count in enumerate(cluster_accident_counts):\n",
    "    plt.scatter(centers[i, 1], centers[i, 0], c='black', s=100, alpha=0.75, marker='X')\n",
    "    plt.text(centers[i, 1], centers[i, 0], str(count), color='black', fontsize=12, ha='left', va='bottom')\n",
    "\n",
    "plt.title('Accidents Region-wise Clustering Without Bumps')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend(title='Region', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f450e05",
   "metadata": {},
   "source": [
    "The cluster shows most happening without bumps. The North-East region has a dense concentration of accidents, which might correspond to an urbanized area with heavy traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455cd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data to include only rows with 'Bumps' being False\n",
    "no_bump_data = df[df['Bump'] == True]\n",
    "\n",
    "# Defining regions based on the median values of latitude and longitude\n",
    "median_lat = no_bump_data['Start_Lat'].median()\n",
    "median_lng = no_bump_data['Start_Lng'].median()\n",
    "\n",
    "# Functioning to determine the region based on latitude and longitude\n",
    "def determine_region(lat, lng, median_lat, median_lng):\n",
    "    if lat >= median_lat and lng >= median_lng:\n",
    "        return 'North-East'\n",
    "    elif lat < median_lat and lng >= median_lng:\n",
    "        return 'South-East'\n",
    "    elif lat >= median_lat and lng < median_lng:\n",
    "        return 'North-West'\n",
    "    else:\n",
    "        return 'South-West'\n",
    "\n",
    "# Applying the function to create a new 'Region' column\n",
    "no_bump_data['Region'] = no_bump_data.apply(lambda x: determine_region(x['Start_Lat'], x['Start_Lng'], median_lat, median_lng), axis=1)\n",
    "\n",
    "# Using KMeans to cluster the data based on 'Latitude' and 'Longitude'\n",
    "kmeans = KMeans(n_clusters=4)  # We choose 4 to match the number of regions we've defined\n",
    "no_bump_data['Cluster'] = kmeans.fit_predict(no_bump_data[['Start_Lat', 'Start_Lng']])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# We are using hue to color the data points based on the new 'Region' column\n",
    "sns.scatterplot(data=no_bump_data, x='Start_Lng', y='Start_Lat', hue='Region', style='Cluster',\n",
    "                palette='Set1', alpha=0.6)\n",
    "\n",
    "# Plotting the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Counting the number of accidents per cluster\n",
    "cluster_accident_counts = no_bump_data.groupby('Cluster').size()\n",
    "\n",
    "# Annotating the cluster centers with the accident counts\n",
    "for i, count in enumerate(cluster_accident_counts):\n",
    "    plt.scatter(centers[i, 1], centers[i, 0], c='black', s=100, alpha=0.75, marker='X')\n",
    "    plt.text(centers[i, 1], centers[i, 0], str(count), color='black', fontsize=12, ha='left', va='bottom')\n",
    "\n",
    "plt.title('Accidents Region-wise Clustering with Bumps')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend(title='Region', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20247bd",
   "metadata": {},
   "source": [
    "The cluster shows least accidents happening with inclusion of speed bumps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f27a6",
   "metadata": {},
   "source": [
    "**Summary of Finding:** Regions with signal bumps tend to have lower accident counts, indicating that bumps may contribute to road safety and accident prevention.\n",
    "\n",
    "**Validity of Finding:** The clustering figure shows clear patterns where regions without and with signal bumps (represented by different clusters colors) have varying accident counts.\n",
    "\n",
    "**Managerial Insights:** Get more bumps! The government should increase the number of signal bumps in high-accident areas could effectively reduce accident rates. Companies involved in road safety solutions could see increased demand for signal bumps and related traffic-calming products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379dee1",
   "metadata": {},
   "source": [
    "## 3) Analysis of Weather Conditions vs Visibility and Severity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_bins = {\n",
    "        'Clear': ['Clear', 'Fair'],\n",
    "        'Cloudy': ['Cloudy', 'Mostly Cloudy', 'Partly Cloudy', 'Scattered Clouds', 'Overcast'],\n",
    "        'Rainy': ['Light Rain', 'Rain', 'Light Freezing Drizzle', 'Light Drizzle', 'Heavy Rain', 'Light Freezing Rain', 'Drizzle', 'Light Freezing Fog', 'Light Rain Showers', 'Showers in the Vicinity', 'T-Storm', 'Thunder', 'Patches of Fog', 'Heavy T-Storm', 'Heavy Thunderstorms and Rain', 'Funnel Cloud', 'Heavy T-Storm / Windy', 'Heavy Thunderstorms and Snow', 'Rain / Windy', 'Heavy Rain / Windy', 'Squalls', 'Heavy Ice Pellets', 'Thunder / Windy', 'Drizzle and Fog', 'T-Storm / Windy', 'Smoke / Windy', 'Haze / Windy', 'Light Drizzle / Windy', 'Widespread Dust / Windy', 'Wintry Mix', 'Wintry Mix / Windy', 'Light Snow with Thunder', 'Fog / Windy', 'Snow and Thunder', 'Sleet / Windy', 'Heavy Freezing Rain / Windy', 'Squalls / Windy', 'Light Rain Shower / Windy', 'Snow and Thunder / Windy', 'Light Sleet / Windy', 'Sand / Dust Whirlwinds', 'Mist / Windy', 'Drizzle / Windy', 'Duststorm', 'Sand / Dust Whirls Nearby', 'Thunder and Hail', 'Freezing Rain / Windy', 'Light Snow Shower / Windy', 'Partial Fog', 'Thunder / Wintry Mix / Windy', 'Patches of Fog / Windy', 'Rain and Sleet', 'Light Snow Grains', 'Partial Fog / Windy', 'Sand / Dust Whirlwinds / Windy', 'Heavy Snow with Thunder', 'Heavy Blowing Snow', 'Low Drifting Snow', 'Light Hail', 'Light Thunderstorm', 'Heavy Freezing Drizzle', 'Light Blowing Snow', 'Thunderstorms and Snow', 'Heavy Rain Showers', 'Rain Shower / Windy', 'Sleet and Thunder', 'Heavy Sleet and Thunder', 'Drifting Snow / Windy', 'Shallow Fog / Windy', 'Thunder and Hail / Windy', 'Heavy Sleet / Windy', 'Sand / Windy', 'Heavy Rain Shower / Windy', 'Blowing Snow Nearby', 'Blowing Sand', 'Heavy Rain Shower', 'Drifting Snow', 'Heavy Thunderstorms with Small Hail'],\n",
    "        'Harsh Conditions':['Light Snow', 'Snow', 'Light Snow / Windy', 'Snow Grains', 'Snow Showers', 'Snow / Windy', 'Light Snow and Sleet', 'Snow and Sleet', 'Light Snow and Sleet / Windy', 'Snow and Sleet / Windy','Blowing Dust / Windy', 'Fair / Windy', 'Mostly Cloudy / Windy', 'Light Rain / Windy', 'T-Storm / Windy', 'Blowing Snow / Windy', 'Freezing Rain / Windy', 'Light Snow and Sleet / Windy', 'Sleet and Thunder / Windy', 'Blowing Snow Nearby', 'Heavy Rain Shower / Windy','Hail','Volcanic Ash','Tornado']\n",
    "        #'Snowy': ['Light Snow', 'Snow', 'Light Snow / Windy', 'Snow Grains', 'Snow Showers', 'Snow / Windy', 'Light Snow and Sleet', 'Snow and Sleet', 'Light Snow and Sleet / Windy', 'Snow and Sleet / Windy'],\n",
    "        #'Windy': ['Blowing Dust / Windy', 'Fair / Windy', 'Mostly Cloudy / Windy', 'Light Rain / Windy', 'T-Storm / Windy', 'Blowing Snow / Windy', 'Freezing Rain / Windy', 'Light Snow and Sleet / Windy', 'Sleet and Thunder / Windy', 'Blowing Snow Nearby', 'Heavy Rain Shower / Windy'],\n",
    "        #'Hail': ['Hail'],\n",
    "        #'Volcanic Ash': ['Volcanic Ash'],\n",
    "        #'Tornado': ['Tornado']\n",
    "\n",
    "}\n",
    "\n",
    "def map_weather_to_bins(weather):\n",
    "    for bin_name, bin_values in weather_bins.items():\n",
    "        if weather in bin_values:\n",
    "            return bin_name\n",
    "    return 'Other' \n",
    "\n",
    "df_11['Weather_Bin'] = df_11['Weather_Condition'].apply(map_weather_to_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ff63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values and their counts in the 'Severity' column\n",
    "WeatherBin_counts = df_11['Weather_Bin'].value_counts()\n",
    "\n",
    "WeatherBin_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df604a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset for the specified weather conditions\n",
    "df_clear = df_11[df_11['Weather_Bin'] == 'Clear']\n",
    "df_cloudy = df_11[df_11['Weather_Bin'] == 'Cloudy']\n",
    "df_harsh = df_11[df_11['Weather_Bin'] == 'Harsh Conditions']\n",
    "df_rainy = df_11[df_11['Weather_Bin'] == 'Rainy']\n",
    "df_other = df_11[df_11['Weather_Bin'] == 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_clear)\n",
    "len(df_cloudy)\n",
    "len(df_harsh)\n",
    "len(df_rainy)\n",
    "len(df_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean values for visibility and severity for each weather condition\n",
    "clear_visibility_mean = df_clear['Visibility'].mean()\n",
    "clear_severity_mean = df_clear['Severity'].mean()\n",
    "print(\"clear_visibility_mean:\")\n",
    "print(clear_visibility_mean)\n",
    "print(\"clear_severity_mean:\")\n",
    "print(clear_severity_mean)\n",
    "\n",
    "\n",
    "cloudy_visibility_mean = df_cloudy['Visibility'].mean()\n",
    "cloudy_severity_mean = df_cloudy['Severity'].mean()\n",
    "print(\"cloudy_visibility_mean:\")\n",
    "print(cloudy_visibility_mean)\n",
    "print(\"cloudy_severity_mean:\")\n",
    "print(cloudy_severity_mean)\n",
    "\n",
    "harsh_visibility_mean = df_harsh['Visibility'].mean()\n",
    "harsh_severity_mean = df_harsh['Severity'].mean()\n",
    "print(\"harsh_visibility_mean:\")\n",
    "print(harsh_visibility_mean)\n",
    "print(\"harsh_severity_mean:\")\n",
    "print(harsh_severity_mean)\n",
    "\n",
    "rainy_visibility_mean = df_rainy['Visibility'].mean()\n",
    "rainy_severity_mean = df_rainy['Severity'].mean()\n",
    "print(\"rainy_visibility_mean:\")\n",
    "print(rainy_visibility_mean)\n",
    "print(\"rainy_severity_mean:\")\n",
    "print(rainy_severity_mean)\n",
    "\n",
    "other_visibility_mean = df_other['Visibility'].mean()\n",
    "other_severity_mean = df_other['Severity'].mean()\n",
    "print(\"other_visibility_mean:\")\n",
    "print(other_visibility_mean)\n",
    "print(\"other_severity_mean:\")\n",
    "print(other_severity_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ab5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total records and severity distribution percentages for each weather condition\n",
    "clear_total_records = len(df_clear)\n",
    "clear_severity_1 = len(df_clear[df_clear['Severity'] == 1])\n",
    "clear_severity_2 = len(df_clear[df_clear['Severity'] == 2])\n",
    "clear_severity_3 = len(df_clear[df_clear['Severity'] == 3])\n",
    "clear_severity_4 = len(df_clear[df_clear['Severity'] == 4])\n",
    "clear_severity_1_pct = (clear_severity_1 / clear_total_records) * 100\n",
    "clear_severity_2_pct = (clear_severity_2 / clear_total_records) * 100\n",
    "clear_severity_3_pct = (clear_severity_3 / clear_total_records) * 100\n",
    "clear_severity_4_pct = (clear_severity_4 / clear_total_records) * 100\n",
    "\n",
    "harsh_total_records = len(df_harsh)\n",
    "harsh_severity_1 = len(df_harsh[df_harsh['Severity'] == 1])\n",
    "harsh_severity_2 = len(df_harsh[df_harsh['Severity'] == 2])\n",
    "harsh_severity_3 = len(df_harsh[df_harsh['Severity'] == 3])\n",
    "harsh_severity_4 = len(df_harsh[df_harsh['Severity'] == 4])\n",
    "harsh_severity_1_pct = (harsh_severity_1 / harsh_total_records) * 100\n",
    "harsh_severity_2_pct = (harsh_severity_2 / harsh_total_records) * 100\n",
    "harsh_severity_3_pct = (harsh_severity_3 / harsh_total_records) * 100\n",
    "harsh_severity_4_pct = (harsh_severity_4 / harsh_total_records) * 100\n",
    "\n",
    "cloudy_total_records = len(df_cloudy)\n",
    "cloudy_severity_1 = len(df_cloudy[df_cloudy['Severity'] == 1])\n",
    "cloudy_severity_2 = len(df_cloudy[df_cloudy['Severity'] == 2])\n",
    "cloudy_severity_3 = len(df_cloudy[df_cloudy['Severity'] == 3])\n",
    "cloudy_severity_4 = len(df_cloudy[df_cloudy['Severity'] == 4])\n",
    "cloudy_severity_1_pct = (cloudy_severity_1 / cloudy_total_records) * 100\n",
    "cloudy_severity_2_pct = (cloudy_severity_2 / cloudy_total_records) * 100\n",
    "cloudy_severity_3_pct = (cloudy_severity_3 / cloudy_total_records) * 100\n",
    "cloudy_severity_4_pct = (cloudy_severity_4 / cloudy_total_records) * 100\n",
    "\n",
    "rainy_total_records = len(df_rainy)\n",
    "rainy_severity_1 = len(df_rainy[df_rainy['Severity'] == 1])\n",
    "rainy_severity_2 = len(df_rainy[df_rainy['Severity'] == 2])\n",
    "rainy_severity_3 = len(df_rainy[df_rainy['Severity'] == 3])\n",
    "rainy_severity_4 = len(df_rainy[df_rainy['Severity'] == 4])\n",
    "rainy_severity_1_pct = (rainy_severity_1 / rainy_total_records) * 100\n",
    "rainy_severity_2_pct = (rainy_severity_2 / rainy_total_records) * 100\n",
    "rainy_severity_3_pct = (rainy_severity_3 / rainy_total_records) * 100\n",
    "rainy_severity_4_pct = (rainy_severity_4 / rainy_total_records) * 100\n",
    "\n",
    "\n",
    "other_total_records = len(df_other)\n",
    "other_severity_1 = len(df_other[df_other['Severity'] == 1])\n",
    "other_severity_2 = len(df_other[df_other['Severity'] == 2])\n",
    "other_severity_3 = len(df_other[df_other['Severity'] == 3])\n",
    "other_severity_4 = len(df_other[df_other['Severity'] == 4])\n",
    "other_severity_1_pct = (other_severity_1 / other_total_records) * 100\n",
    "other_severity_2_pct = (other_severity_2 / other_total_records) * 100\n",
    "other_severity_3_pct = (other_severity_3 / other_total_records) * 100\n",
    "other_severity_4_pct = (other_severity_4 / other_total_records) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the calculated means and percentages\n",
    "mean_values_and_percentages = {\n",
    "    'Weather': ['Clear', 'Harsh Conditions', 'Cloudy','Rainy','Other'],\n",
    "    'Visibility Mean': [clear_visibility_mean, harsh_visibility_mean, cloudy_visibility_mean, rainy_visibility_mean, other_visibility_mean],\n",
    "    'Severity Mean': [clear_severity_mean, harsh_severity_mean, cloudy_severity_mean, rainy_severity_mean, other_severity_mean],\n",
    "    'Total Records': [clear_total_records, harsh_total_records, cloudy_total_records, rainy_total_records, other_total_records],\n",
    "    'Severity 1': [clear_severity_1_pct, harsh_severity_1_pct, cloudy_severity_1_pct, rainy_severity_1_pct, other_severity_1_pct],\n",
    "    'Severity 2': [clear_severity_2_pct, harsh_severity_2_pct, cloudy_severity_2_pct, rainy_severity_2_pct, other_severity_2_pct],\n",
    "    'Severity 3': [clear_severity_3_pct, harsh_severity_3_pct, cloudy_severity_3_pct, rainy_severity_3_pct, other_severity_3_pct],\n",
    "    'Severity 4': [clear_severity_4_pct, harsh_severity_4_pct, cloudy_severity_4_pct, rainy_severity_4_pct, other_severity_4_pct]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c33ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dictionary to a DataFrame for plotting\n",
    "df_summary = pd.DataFrame(mean_values_and_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a heatmap for the calculated mean values and percentages\n",
    "# We need to transpose the summary DataFrame to have Weather Conditions as columns for the heatmap\n",
    "df_summary_transposed = df_summary.set_index('Weather').T\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_summary_transposed, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=.3)\n",
    "plt.title(\"Heatmap of Weather Conditions vs Visibility and Severity Metrics\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45cf16",
   "metadata": {},
   "source": [
    "**Key Insights**\n",
    "1. Harsh Conditions show a significantly lower visibility mean, which suggests that such weather conditions can substantially reduce visibility. \n",
    "2. It is surprising to see that the severity mean does not vary significantly across different weather conditions, indicating that the weather might not drastically change the average severity of occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcdffd",
   "metadata": {},
   "source": [
    "**Managerial recommendation:**\n",
    "\n",
    "Impact on ADAS (Advanced Driving Assistance System):\n",
    "\n",
    "In Harsh Conditions, where visibility is significantly reduced, ADAS features like adaptive headlights, night vision systems, and forward-collision warnings should adapt according to above insights and assist in detecting obstacles on the road and help prevent accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcff00",
   "metadata": {},
   "source": [
    "### Impact on Distance(mi) against Severity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ba3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_distance_severity_1 = df_11.loc[df_11['Severity'] == 1, 'Distance'].sum()\n",
    "count_distance_severity_1 = df_11.loc[df_11['Severity'] == 1, 'Distance'].count()\n",
    "\n",
    "print(\"Sum of Distance for Severity 1:\", sum_distance_severity_1)\n",
    "print(\"Count of Distance for Severity 1:\", count_distance_severity_1)\n",
    "Distance_Sev1 = sum_distance_severity_1/count_distance_severity_1\n",
    "Distance_Sev1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_distance_severity_2 = df_11.loc[df_11['Severity'] == 2, 'Distance'].sum()\n",
    "count_distance_severity_2 = df_11.loc[df_11['Severity'] == 2, 'Distance'].count()\n",
    "\n",
    "print(\"Sum of Distance for Severity 2:\", sum_distance_severity_2)\n",
    "print(\"Count of Distance for Severity 2:\", count_distance_severity_2)\n",
    "Distance_Sev2 = sum_distance_severity_2/count_distance_severity_2\n",
    "Distance_Sev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_distance_severity_3 = df_11.loc[df_11['Severity'] == 3, 'Distance'].sum()\n",
    "count_distance_severity_3 = df_11.loc[df_11['Severity'] == 3, 'Distance'].count()\n",
    "\n",
    "print(\"Sum of Distance for Severity 3:\", sum_distance_severity_3)\n",
    "print(\"Count of Distance for Severity 3:\", count_distance_severity_3)\n",
    "Distance_Sev3 = sum_distance_severity_3/count_distance_severity_3\n",
    "Distance_Sev3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_distance_severity_4 = df_11.loc[df_11['Severity'] == 4, 'Distance'].sum()\n",
    "count_distance_severity_4 = df_11.loc[df_11['Severity'] == 4, 'Distance'].count()\n",
    "\n",
    "print(\"Sum of Distance for Severity 4:\", sum_distance_severity_4)\n",
    "print(\"Count of Distance for Severity 4:\", count_distance_severity_4)\n",
    "Distance_Sev4 = sum_distance_severity_4/count_distance_severity_4\n",
    "Distance_Sev4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b053d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_Sev_Means = [Distance_Sev1, Distance_Sev2, Distance_Sev3, Distance_Sev4]\n",
    "severity_values = [1, 2, 3, 4]\n",
    "\n",
    "# Creating a DataFrame from the means and severity values\n",
    "df_means = pd.DataFrame({'Severity': severity_values, 'Mean_Distance': Distance_Sev_Means})\n",
    "\n",
    "# Defining a color palette for each severity level\n",
    "severity_palette = {1: 'green', 2: 'brown', 3: 'orange', 4: 'red'}\n",
    "\n",
    "# Plotting the bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Severity', y='Mean_Distance', data=df_means, palette=severity_palette, width=0.2, dodge=False)\n",
    "plt.title('Bar Plot of Mean Distance against Severity')\n",
    "plt.xlabel('Severity')\n",
    "plt.ylabel('Mean Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a308c",
   "metadata": {},
   "source": [
    "__Key Insight:__ Severity 1 accidents have the shortest mean distance, while Severity 4 accidents impact significantly longer stretches of road. This could indicate that accidents with high severity tend to involve larger areas, potentially due to factors such as more vehicles being involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe1260",
   "metadata": {},
   "source": [
    "**Interesting finding:** \n",
    "Severity 2 accidents, while not the most impactful in terms of traffic delay, affect a longer stretch of road than Severity 3 accidents. \n",
    "This could suggest several scenarios:\n",
    "1. Severity 2 accidents may involve incidents that, although not causing severe traffic delays, cover a larger area. This might be due to incidents that result in obstructions or hazards spread over a greater distance, causing moderate traffic slowdowns.\n",
    "\n",
    "2. Severity 3 accidents, while affecting a smaller area, could be more concentrated and cause significant delays, possibly due to the road being blocked or more intensive emergency services response required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae88476",
   "metadata": {},
   "source": [
    "## Collaborating Interesting findings and respective Managerial Recommendations below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721cdab1",
   "metadata": {},
   "source": [
    "1) a) **Insight** : \n",
    "    - You will be amazed with the fact that almost 34% of accidents have occoured even though there were Traffic Signal, Crossing and Junction present in location.((Traffic Signal) 14.84 + (Crossing) 11.35 + (Junction) 7.35 =33.54 %)\n",
    "    - On detailed analysis of these factors by diving the US states into 7 zones based on geographical conditions, it is quite evident from the graph that 68.47% of accidents in south east region occurred even though these 3 factors(Traffic signal,Crossing and Junction) were present there.\n",
    "South East - Traffic Signal) 31.27 + (Crossing) 28.7 + (Junction) 8.50 = 68.47 %\n",
    "\n",
    "   b) **Managerial Recommendation** : \n",
    "    - More penalties must be levied by the Government for traffic rules violations( specially in south east region) so that people would be more cautious while driving and accidents count would be less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1d1c1",
   "metadata": {},
   "source": [
    "2. a) **Insight** : \n",
    "    - Regions with signal bumps tend to have lower accident counts, indicating that bumps may contribute to road safety and accident prevention.\n",
    "\n",
    "\n",
    "   b) **Managerial Insights:** \n",
    "    - Get more bumps! The government should increase the number of signal bumps in high-accident areas could effectively reduce accident rates. Companies involved in road safety solutions could see increased demand for signal bumps and related traffic-calming products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603ecae",
   "metadata": {},
   "source": [
    "3. a) **Insight**\n",
    "    - It is surprising to see that the severity mean does not vary significantly across different weather conditions, indicating that the weather might not drastically change the average severity of occurrences.\n",
    "    \n",
    "   b) **Managerial recommendation:**\n",
    "    - Impact on ADAS (Advanced Driving Assistance System): In Harsh Conditions, where visibility is significantly reduced, ADAS features like adaptive headlights, night vision systems, and forward-collision warnings should adapt according to above insights and assist in detecting obstacles on the road and help prevent accidents.\n",
    "    \n",
    "    *(Note: ADAS system is typically used in self-driving cars and automotives.)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
